name: Run Benchmarks

# Run this action when triggered manually through GitHub UI.
on:
  workflow_dispatch:
    inputs:
      timeout:
        required: true
        type: number
        default: 20
      config:
        required: true
        type: choice
        default: loat_sat
        options:
        - loat_sat
        - loat_unsat
        - loat_nonterm
        - loat_lb
        - z3_gspacer
        - z3_spacer
        - z3_bmc
      benchmarks:
        required: true
        type: choice
        default: chc23-lia-lin
        options:
        - chc22-lia-lin
        - chc23-lia-lin

permissions:
  # deployments permission to deploy GitHub pages website
  deployments: write
  # contents permission to update benchmark contents in gh-pages branch
  contents: write

jobs:

  chc-comp-benchmark:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        ci_index: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]
        ci_total: [20]

    steps:

      - name: Checkout LoAT Repository
        uses: actions/checkout@v4
        with:
          sparse-checkout: .github/actions
          path: actions

      - if: ${{ inputs.benchmarks == 'chc23-lia-lin' }}
        uses: ./actions/.github/actions/chc23-lia-lin

      - if: ${{ inputs.benchmarks == 'chc22-lia-lin' }}
        uses: ./actions/.github/actions/chc22-lia-lin

      - if: ${{ startsWith(inputs.config, 'loat') }}
        uses: ./actions/.github/actions/get-loat

      - if: ${{ startsWith(inputs.config, 'z3') }}
        uses: ./actions/.github/actions/get-z3

      - name: Run Benchmark
        run: |
          # function to run a single benchmark
          function benchmark() {
            filename=$1
            printf "running ${filename} ... "
            start=`date +%s.%N`

            set +e
            if [ ${{ inputs.config }} = "loat_sat" ]; then
              result=$(timeout ${{ inputs.timeout }} solver --mode safety --format horn --proof-level 0 --engine til --til::mode interleaved "${filename}")
            elif [ ${{ inputs.config }} = "loat_unsat" ]; then
              result=$(timeout ${{ inputs.timeout }} solver --mode reachability --format horn --proof-level 0 --engine abmc "${filename}")
            elif [ ${{ inputs.config }} = "loat_nonterm" ]; then
              result=$(timeout ${{ inputs.timeout }} solver --mode non_termination --format its --proof-level 0 --engine adcl "${filename}")
            elif [ ${{ inputs.config }} = "loat_lb" ]; then
              result=$(timeout ${{ inputs.timeout }} solver --mode complexity --format koat --proof-level 0 --engine adcl "${filename}")
            elif [ ${{ inputs.config }} = "z3_gspacer" ]; then
              result=$(timeout ${{ inputs.timeout }} solver fp.engine=spacer fp.spacer.global=true "${filename}")
            elif [ ${{ inputs.config }} = "z3_spacer" ]; then
              result=$(timeout ${{ inputs.timeout }} solver fp.engine=spacer "${filename}")
            elif [ ${{ inputs.config }} = "z3_bmc" ]; then
              result=$(timeout ${{ inputs.timeout }} solver fp.engine=bmc "${filename}")
            fi

            exit_status=$?
            set -e

            end=`date +%s.%N`
            runtime=$( echo "$end - $start" | bc -l )
            runtime=$( printf %.2f $runtime )

            if [[ $exit_status -eq 0 ]]; then
              result=$(echo "$result" | head -n 1)
            elif [[ $exit_status -eq 124 ]]; then
              result="timeout"
            else
              result="error"
            fi

            printf "${result} after ${runtime}s\n"

            echo -e "{\"name\": \"$filename\", \"result\": \"$result\", \"runtime\": \"$runtime\"}," >> ${filename}.json
          }

          # make 'benchmark' available for 'parallel'
          export -f benchmark

          # permissions are not preserved for artifacts:
          chmod +x /usr/local/bin/solver

          cd benchmarks

          # remove benchmarks that are executed by other workers
          i=0
          for filename in *.smt2; do
            if [[ $(( i % CI_TOTAL )) -ne $CI_INDEX ]]; then
              rm ${filename}
            fi
            i=$(( i+1 ))
          done

          if [[ 0 -eq $CI_INDEX ]]; then
             echo $VERSION > solver.version
          fi

          # execute benchmarks in parallel
          parallel benchmark ::: *.smt2

        env:
          CI_TOTAL: ${{ matrix.ci_total }}
          CI_INDEX: ${{ matrix.ci_index }}

      - name: Upload Benchmark Results
        uses: actions/upload-artifact@master
        with:
          name: ${{ inputs.benchmarks }}-${{ matrix.ci_index }}
          path: |
            benchmarks/*.json
            benchmarks/*.version

  finalize-benchmark-results:
    needs: [chc-comp-benchmark]
    runs-on: ubuntu-latest
    steps:

      - name: Checkout LoAT Repository
        uses: actions/checkout@v4
        with:
          sparse-checkout: benchmarks

      - run: mkdir -p benchmarks/${{ inputs.benchmarks }}

      - uses: actions/download-artifact@v4
        with:
          pattern: ${{ inputs.benchmarks }}*

      - name: Merge Benchmark Results
        run: |
          declare -A results
          VERSION=$(cat ${{ inputs.benchmarks }}-0/solver.version)
          echo "VERSION=${VERSION}" >> $GITHUB_ENV
          results="./benchmarks/${{ inputs.benchmarks }}/${{ inputs.config }}-$VERSION.json"
          echo -e "{\n" >> $results
          echo -e "\t\"benchmarks\": \"${{ inputs.benchmarks }}\"," >> $results
          echo -e "\t\"config\": \"${{ inputs.config }}\"," >> $results
          echo -e "\t\"branch\": \"${{ github.ref_name }}\"," >> $results
          echo -e "\t\"sha\": \"$version\"," >> $results
          echo -e "\t\"results\": [" >> $results
          for filename in ${{ inputs.benchmarks }}*/*.json; do
            json=$(cat $filename)
            echo -e "\t\t$json," >> $results
          done
          echo -e "\t]" >> $results
          echo -e "}" >> $results

      -  uses: EndBug/add-and-commit@v9
         with:
           add: 'benchmarks'
           author_name: Florian Frohn
           author_email: florian.frohn@cs.rwth-aachen.de
           fetch: false
           message: 'benchmark results; config ${{ inputs.config }}; benchmarks: ${{ inputs.benchmarks }}'
